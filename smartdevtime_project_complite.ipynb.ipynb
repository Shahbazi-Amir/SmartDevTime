{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c81d0031",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; white-space: pre-wrap; line-height: 1.5;\">\n",
    "\n",
    "\n",
    "# خلاصهٔ اجرایی (TL;DR)\n",
    "\n",
    "* **پروژه ۱ (واقعی \\~۸۱ → پاک‌سازی \\~۷۷ ردیف)**: بهترین مدل «رگرسیون خطی» با R²≈0.44 و MAE≈2024 (روی متغیر Effort). داده کم است؛ برای پیش‌بینی زمان دقیق قابل‌اتکای عملیاتی کافی نیست، ولی برای MVP داخلی با «بازهٔ عدم‌قطعیت» می‌تواند استفاده شود. جزئیات و همین اعداد در README هم آمده‌اند. ([GitHub][1])\n",
    "* **پروژه ۲ (۸۰ واقعی + تا ۳۰۰ شبیه‌سازی‌شده)**: روی «Log(Effort)» ولیدیشن درست‌تر داری؛ میانگین نتایج CV برای مدل‌ها حدود R²≈0.42–0.52 است. بهترین بلوک‌ها:\n",
    "\n",
    "  * **Random Forest (۵×۲ CV)**: R²≈0.52±0.16، MAE≈2074±253، RMSE≈2637±310 (روی Effort اصلی).\n",
    "  * مدل‌های خطی/الاستیک‌نت/لسو روی مقیاس لگ نیز پایدار و نزدیک‌اند (MAE لگ ≈0.48–0.65).\n",
    "* **ساید‌پروژه (گیت‌هاب \\~۳۷k)**:\n",
    "\n",
    "  * برای **مدت‌زمان repo (duration\\_days)**: خطی با ۵-Fold R²≈0.06 (خیلی پایین).\n",
    "  * نسخهٔ «XGBoost با فیچرهای تجمعی» به R²≈0.993 رسیده که **تقریباً قطعاً لیکیج** است (از فیچرهایی مثل ستاره/فورک/PR که خودشان با طول‌عمر رشد می‌کنند). بنابراین برای «پیش‌بینی زمان پروژه قبل از شروع» مناسب نیست.\n",
    "* **نتیجهٔ عملی**: برای دیپلوی بیرونی که «زمان دقیق» بدهد، **هنوز زود است**. پیشنهاد: یا یک **API داخلی آزمایشی** با بازهٔ پیش‌بینی و هشدار عدم قطعیت بسازیم، یا اول **دادهٔ واقعی بیشتر** جمع کنیم و سپس دیپلوی کنیم.\n",
    "* **آیا همین حالا بسازیم یا برویم دنبال دادهٔ واقعی؟** با توجه به خطاها و اندازهٔ داده، **قطعی: دادهٔ واقعی بیشتر** (حداقل ۳۰۰–۵۰۰ رکورد هم‌حوزه) اولویت دارد. سپس دیپلوی با اعتمادبه‌نفس بالا.\n",
    "\n",
    "---\n",
    "\n",
    "# جزئیات هر پروژه\n",
    "\n",
    "## 1) پروژهٔ ۱ — دادهٔ واقعی کم‌حجم (fp.csv)\n",
    "\n",
    "* **اندازه و اسکیمای کلی**: منبع 81×13، بعد از پاک‌سازی حدود 77 ردیف؛ فیچرهایی مثل تجربهٔ تیم/مدیر، متریک‌های کدی، زبان و… (این توی README هم مستند شده). ([GitHub][1])\n",
    "* **ولیدیشن/مدل‌ها**: یک Train/Test split ساده.\n",
    "* **نتایج کلیدی** (از نوت‌بوک و README):\n",
    "\n",
    "  * Linear (best): **R²≈0.44، MAE≈2024، RMSE≈2831**.\n",
    "  * DecisionTree/RandomForest/XGBoost ضعیف‌تر از خطی—حجم کم داده دلیل اصلی است. ([GitHub][1])\n",
    "* **برداشت**: دادهٔ واقعی است، ولی کم؛ با این اندازه، عدم قطعیت بالاست. برای MVP داخلی با بازهٔ پیش‌بینی می‌شود، برای بیرونی نه.\n",
    "\n",
    "## 2) پروژهٔ ۲ — ۸۰ واقعی + تا ۳۰۰ شبیه‌سازی‌شده (Desharnais expanded)\n",
    "\n",
    "* **اندازه**: خروجی «df» \\~۳۰۰×۱۳ (real+sim).\n",
    "* **پروتکل درست‌تر**: کار روی **Log(Effort)**، استفاده از **۵-fold** و حتی **۵×۲ CV**، و مقایسهٔ چند مدل (Linear/Ridge/Lasso/ElasticNet/RandomForest/XGBoost).\n",
    "* **نمونهٔ نتایج** (از خروجی‌های نوت‌بوک):\n",
    "\n",
    "  * Baseline روی لگ: CV **MAE≈0.49**، **RMSE≈0.65**، **R²≈0.42** (به لگ).\n",
    "  * برگردان به Effort اصلی (یک اجرا): **MAE≈2160–2170**، **RMSE≈3227–3257**، **R²≈0.45**.\n",
    "  * **Random Forest (۵×۲ CV)**: **R²≈0.52±0.16**، **MAE≈2074±253**، **RMSE≈2637±310**.\n",
    "  * XGBoost سبک: R²≈0.42±0.20 (نوسانی‌تر).\n",
    "* **برداشت**: با CV بهتر شده‌ای، ولی **دادهٔ شبیه‌سازی‌ای** ریسک شیفت دامنه دارد. به‌عنوان **مدل پایهٔ داخلی** بد نیست، اما برای دیپلوی بیرونی باید با دادهٔ واقعی بازآموزی و اعتبارسنجی شود.\n",
    "\n",
    "## 3) سایدپروژه — دادهٔ GitHub (\\~37k)\n",
    "\n",
    "* **هدف‌های مختلف**:\n",
    "\n",
    "  * یک بخش برای **contributors** (R²≈0.68 با XGB/RF) — مسئلهٔ دیگری‌ست.\n",
    "  * بخش اصلی ما اینجاست: **پیش‌بینی duration\\_days** = lastActivityAt − createdAt.\n",
    "* **نتایج duration\\_days**:\n",
    "\n",
    "  * Linear + 5-Fold: **R²≈0.06**، **MAE≈450 روز**، **RMSE≈551 روز** → عملاً توضیح نمی‌دهد.\n",
    "  * نسخهٔ «XGBoost + فیچرهای تجمعی (ستاره/فورک/PR/واچرز…)»: **R²≈0.993** → **لیکِیج شدید**؛ چون این فیچرها مستقیماً با طول عمر زیاد می‌شوند و پیش‌بینی قبل از شروع پروژه را بی‌اعتبار می‌کنند.\n",
    "* **برداشت**: این داده برای هدف «زمان‌بندی پیش از شروع» مناسب نیست مگر این‌که فقط از **فیچرهای پیشینی** (شناخته‌شدنی قبل از شروع) استفاده کنیم.\n",
    "\n",
    "---\n",
    "\n",
    "# آیا می‌توان الآن دیپلوی کرد؟\n",
    "\n",
    "**به‌صورت محصول بیرونی با عدد دقیق: نه هنوز.**\n",
    "اما می‌توان یک **MVP داخلی** به‌صورت API ساخت که:\n",
    "\n",
    "1. فقط از **فیچرهایی که پیش از شروع پروژه در دسترس‌اند** استفاده کند (مثلاً TeamExp/ManagerExp، پیچیدگی/تخمین FP، اندازه تیم، حوزه، پلتفرم و …).\n",
    "2. خروجی را به‌صورت **بازهٔ پیش‌بینی (Prediction Interval)** برگرداند (مثلاً صدک‌های ۱۰/۵۰/۹۰ یا Quantile Regression)، نه فقط نقطهٔ واحد.\n",
    "3. **هشدار عدم قطعیت** و معیار «اطمینان» بدهد (براساس فاصلهٔ بین صدک‌ها یا انمسامبل).\n",
    "4. لاگ و مانیتورینگ داشته باشد تا بعد از جمع‌کردن دادهٔ واقعی، **بازکالیبراسیون** کنیم.\n",
    "\n",
    "> اگر بخواهیم همین امروز MVP بسازیم:\n",
    "> **Pipeline پیشنهادی v0.1** = *RidgeCV روی Log(Effort)* یا *RandomForest محدود و کم‌پیچیدگی* + **کالیبراسیون صدکی** + **Feature set پیشینیِ کوچک**. انتظار کارایی نزدیک به نتایج پروژه ۱/۲، با شفاف‌سازی بازهٔ خطا.\n",
    "\n",
    "---\n",
    "\n",
    "# آیا سراغ دادهٔ واقعی بیشتر برویم یا همین حالا کافی است؟\n",
    "\n",
    "**قطعاً دادهٔ واقعی بیشتر.**\n",
    "\n",
    "* حداقل **۳۰۰–۵۰۰ نمونهٔ واقعی هم‌دامنه** (از همان نوع پروژه‌ها/سازمان/فرایند).\n",
    "* یکنواخت‌سازی واحد Effort (ساعت/نفر-ساعت/نفر-روز)، تعریف یکتا برای «تمام‌شدن»، یکسان‌سازی ابزار ثبت داده.\n",
    "* ثبت **فیچرهای «پیشینی»** که در لحظهٔ برآورد واقعاً موجودند:\n",
    "\n",
    "  * TeamExp، ManagerExp (با تعریف شفاف و بدون -1)\n",
    "  * تخمین اندازه/پیچیدگی (FP یا Story Points + کلاس پیچیدگی)\n",
    "  * اندازهٔ تیم، مدل همکاری (in-house/outsourcing)، حوزهٔ دامنه، تکنولوژی‌های اصلی، ریسک‌های شناخته‌شده، محدودیت‌های غیر‌فنی (compliance، vendor)\n",
    "  * پرهیز از هر فیچری که بعداً و با گذر زمان شکل می‌گیرد (مثل تعداد PRها/کامیت‌ها/فورک‌ها/ستاره‌ها و…).\n",
    "\n",
    "---\n",
    "\n",
    "# نکات کدنویسی و اعتبارسنجی (بر اساس بررسی نوت‌بوک‌ها)\n",
    "\n",
    "* ✅ **Log-transform** روی Effort در پروژه ۲ کار درستی بود؛ ولی **بایاس برگشت از لگ** را با روش‌های تصحیح (مثلاً «داوریان» یا بوت‌استرپ) مدیریت کن.\n",
    "* ⚠️ **لیکِیج** در سایدپروژه (فیچرهای تجمعی زمان‌مند) را حذف کن؛ فقط فیچرهای پیشینی مجاز.\n",
    "* ⚠️ **ولیدیشن**: پروژه ۱ یک Split ثابت داشت؛ بهتر است **Repeated KFold (۵×۲)** یا **CV با گروه پروژه/سال** داشته باشیم. اگر ستون YearEnd هست، **Time-aware split** امتحان کن.\n",
    "* ✅ **پایپ‌لاین اسکیکیت‌لِرن** با `ColumnTransformer` + `StandardScaler` + مدل، تا نشت اسکیل/وان-هات رخ ندهد و دیپلوی راحت شود.\n",
    "* ✅ **انتخاب مدل**: روی دادهٔ کوچک، مدل‌های خطی/ریج/الاستیک‌نت غالباً پایدارتر از درختی‌های پیچیده‌اند. RF خوب بود ولی حواست به واریانس باشد.\n",
    "* ✅ **Hyperparam Search**: الان دارید (مثلاً LassoCV). نمرهٔ هدف را **MAE** یا **RMSE** یک‌دست کن و از **Nested CV** برای گزارش نهایی استفاده کن.\n",
    "* ✅ **ثبت نسخه‌ها** (`random_state`، ورژن‌های پکیج‌ها)، **Seed** ثابت، و **Reproducibility** برای تولید مدل نهایی.\n",
    "* ✅ **Calibration/Uncertainty**: کوانتیل-ریگرشن (LightGBM/XGBRegressorQuantile) یا بوت‌استرپ برای بازه‌های اعتماد.\n",
    "\n",
    "---\n",
    "\n",
    "# چک‌لیست کوتاه دیپلوی (برای وقتی که آماده شدیم)\n",
    "\n",
    "1. **Schema قفل‌شده** از فیچرهای پیشینی + ولیدیشن ورودی.\n",
    "2. **پایپ‌لاین joblib/pkl**: کدگذاری دسته‌ای، اسکیل، مدل، Post-process برگشت از لگ.\n",
    "3. **Endpoint ساده** `/predict` (FastAPI) → برگرداندن **P10 / P50 / P90**.\n",
    "4. **Monitoring**: لاگ ورودی/خروجی، توزیع فیچر، خطاها (MAE/SMAPE)، درفت.\n",
    "5. **Data feedback loop**: هر پروژهٔ جدید با برچسب «Effort واقعی» به دیتاست برگردد؛ **بازآموزی دوره‌ای** (مثلاً ماهانه).\n",
    "6. **مستندات**: README، مثال ورودی/خروجی، هشدارها و انتظارات.\n",
    "\n",
    "---\n",
    "\n",
    "# منابع و ارجاع\n",
    "\n",
    "* خلاصهٔ پروژه ۱، اندازهٔ دیتاست و متریک‌های نهایی در **README ریپو** آمده و با خروجی‌های نوت‌بوک شما همخوان است. ([GitHub][1])\n",
    "\n",
    "---\n",
    "\n",
    "# گام بعدی پیشنهادی\n",
    "\n",
    "اگر موافقی، من می‌تونم:\n",
    "\n",
    "* یک **گزارش یک‌صفحه‌ای Markdown** با جدول نتایج سه پروژه + چک‌لیست MVP بسازم،\n",
    "* و **Pipeline v0.1** (RidgeCV روی Log(Effort) با فیچرهای پیشینی) را به‌صورت کد تمیز + فایل مدل آمادهٔ دیپلوی تحویل بدهم.\n",
    "\n",
    "## سؤال آموزشی (طبق «پرامپتِ قدم»):\n",
    "\n",
    "**کدام یک از فیچرهای فعلی‌ات «قطعاً پیش از شروع پروژه» معلوم‌اند و کدام‌ها بعد از شروع شکل می‌گیرند؟** (لیستی بنویس—این مرز را هرچه دقیق‌تر کنی، مدل قابل‌دیپلوی‌تر می‌شود.)\n",
    "\n",
    "[1]: https://github.com/Shahbazi-Amir/SmartDevTime \"GitHub - Shahbazi-Amir/SmartDevTime\"\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187b6001",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
